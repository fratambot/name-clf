{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 10:30:30.192472: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#import seaborn as sns\n",
    "\n",
    "import keras_tuner\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_seq_items = 2000\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 800\n",
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.width = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = '/Users/francesco/REPOS/name-clf/app'\n",
    "os.chdir(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.hypermodel import hyperband_tuner, model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7999, 32)\n",
      "(1001, 32)\n"
     ]
    }
   ],
   "source": [
    "with np.load(os.path.join(base_url, \"artifacts/data\", \"Country-datasets.npz\"), allow_pickle=True) as f:\n",
    "    X_train, y_train = f[\"X_train\"], f[\"y_train\"]\n",
    "    X_val, y_val = f[\"X_val\"], f[\"y_val\"]\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_url, \"artifacts\", \"tokenizer.pkl\"), \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_size =  68\n",
      "metrics =  [<keras.metrics.metrics.CategoricalAccuracy object at 0x7fa8ae438700>]\n",
      "softmax_units =  5\n",
      "input_shape =  32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 10:30:40.872205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Params from data\n",
    "embedding_size = len(tokenizer.word_index)\n",
    "print(\"embedding_size = \", embedding_size)\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    "print(\"metrics = \", metrics)\n",
    "softmax_units = y_train.shape[1]\n",
    "print(\"softmax_units = \", softmax_units)\n",
    "input_shape = X_train.shape[1]\n",
    "print(\"input_shape = \", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "my_model = model(input_shape, metrics, softmax_units, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 68)            4692      \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 26, 32)            15264     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 13, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 32)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 13, 32)            8320      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 416)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               53376     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,233\n",
      "Trainable params: 90,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 8s 32ms/step - loss: 1.5211 - categorical_accuracy: 0.2922 - val_loss: 1.4829 - val_categorical_accuracy: 0.2737\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 1.4473 - categorical_accuracy: 0.3468 - val_loss: 1.4447 - val_categorical_accuracy: 0.3546\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 3s 26ms/step - loss: 1.4188 - categorical_accuracy: 0.3610 - val_loss: 1.4248 - val_categorical_accuracy: 0.3756\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 1.3938 - categorical_accuracy: 0.3874 - val_loss: 1.3764 - val_categorical_accuracy: 0.3896\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 2s 16ms/step - loss: 1.3780 - categorical_accuracy: 0.4002 - val_loss: 1.3913 - val_categorical_accuracy: 0.3906\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 1.3752 - categorical_accuracy: 0.3975 - val_loss: 1.3812 - val_categorical_accuracy: 0.3816\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 1.3620 - categorical_accuracy: 0.4116 - val_loss: 1.3918 - val_categorical_accuracy: 0.4006\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 1.3544 - categorical_accuracy: 0.4172 - val_loss: 1.3729 - val_categorical_accuracy: 0.4036\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 1.3452 - categorical_accuracy: 0.4238 - val_loss: 1.3850 - val_categorical_accuracy: 0.3956\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 1.3494 - categorical_accuracy: 0.4181 - val_loss: 1.3975 - val_categorical_accuracy: 0.4086\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 1.3423 - categorical_accuracy: 0.4217 - val_loss: 1.3645 - val_categorical_accuracy: 0.4186\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 1.3292 - categorical_accuracy: 0.4264 - val_loss: 1.3620 - val_categorical_accuracy: 0.4056\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 1.3247 - categorical_accuracy: 0.4303 - val_loss: 1.3758 - val_categorical_accuracy: 0.3956\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 1.3246 - categorical_accuracy: 0.4343 - val_loss: 1.3559 - val_categorical_accuracy: 0.4116\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 1.3230 - categorical_accuracy: 0.4293 - val_loss: 1.3644 - val_categorical_accuracy: 0.4066\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 1.3097 - categorical_accuracy: 0.4383 - val_loss: 1.3783 - val_categorical_accuracy: 0.3796\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 1.3225 - categorical_accuracy: 0.4284 - val_loss: 1.3921 - val_categorical_accuracy: 0.3766\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 1.3050 - categorical_accuracy: 0.4378 - val_loss: 1.3855 - val_categorical_accuracy: 0.4016\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 1.2998 - categorical_accuracy: 0.4369 - val_loss: 1.3629 - val_categorical_accuracy: 0.4176\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 1.3080 - categorical_accuracy: 0.4313 - val_loss: 1.3490 - val_categorical_accuracy: 0.4146\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 3s 27ms/step - loss: 1.2972 - categorical_accuracy: 0.4401 - val_loss: 1.3743 - val_categorical_accuracy: 0.4136\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 1.3001 - categorical_accuracy: 0.4376 - val_loss: 1.3823 - val_categorical_accuracy: 0.4096\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 1.3027 - categorical_accuracy: 0.4396 - val_loss: 1.4069 - val_categorical_accuracy: 0.3966\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 1.3072 - categorical_accuracy: 0.4382 - val_loss: 1.3839 - val_categorical_accuracy: 0.4056\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 3s 28ms/step - loss: 1.2983 - categorical_accuracy: 0.4454 - val_loss: 1.3748 - val_categorical_accuracy: 0.4096\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 4s 29ms/step - loss: 1.3022 - categorical_accuracy: 0.4433 - val_loss: 1.3943 - val_categorical_accuracy: 0.4136\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 1.2992 - categorical_accuracy: 0.4463 - val_loss: 1.3876 - val_categorical_accuracy: 0.3866\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 2s 18ms/step - loss: 1.3050 - categorical_accuracy: 0.4356 - val_loss: 1.3919 - val_categorical_accuracy: 0.4056\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 1.2910 - categorical_accuracy: 0.4383 - val_loss: 1.3969 - val_categorical_accuracy: 0.3986\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 1.3012 - categorical_accuracy: 0.4338 - val_loss: 1.3879 - val_categorical_accuracy: 0.3776\n"
     ]
    }
   ],
   "source": [
    "history=my_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=30, \n",
    "    batch_size=64,\n",
    "    verbose =1,\n",
    "    validation_data=(X_val,y_val)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperband with Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"tuning_country\"\n",
    "directory = \"logs/country_hpt\"\n",
    "tuner = hyperband_tuner(input_shape, metrics, softmax_units, embedding_size, project_name, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "dropout_1 (Float)\n",
      "{'default': 0.3, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "dense_units_1 (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
      "dropout_2 (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "dense_units_2 (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary(extended=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/tb_country_hpt\n"
     ]
    }
   ],
   "source": [
    "hpt_dir = \"logs/tb_country_hpt\"\n",
    "fit_dir = \"logs/tb_country_fit\"\n",
    "print(hpt_dir)\n",
    "tensorboard_callback_htp = tf.keras.callbacks.TensorBoard(log_dir=hpt_dir, histogram_freq=1)\n",
    "tensorboard_callback_fit = tf.keras.callbacks.TensorBoard(log_dir=fit_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated trials:  148.71236723665453\n"
     ]
    }
   ],
   "source": [
    "# Estimated trials simulation:\n",
    "sim_max_epochs = 20\n",
    "sim_iterations = 1\n",
    "sim_factor = 3\n",
    "est_trials = sim_iterations*sim_max_epochs*(math.log(sim_max_epochs, sim_factor))**2\n",
    "print(\"Estimated trials: \", est_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 06s]\n",
      "val_loss: 1.4114619493484497\n",
      "\n",
      "Best val_loss So Far: 1.3295183181762695\n",
      "Total elapsed time: 00h 12m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[tensorboard_callback_htp, tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in logs/country_hpt/tuning_country\n",
      "Showing 3 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fa892636ee0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.1\n",
      "dense_units_1: 128\n",
      "dropout_2: 0.5\n",
      "dense_units_2: 256\n",
      "lr: 0.0007487917450008943\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0020\n",
      "Score: 1.3295183181762695\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.2\n",
      "dense_units_1: 64\n",
      "dropout_2: 0.0\n",
      "dense_units_2: 128\n",
      "lr: 0.0015790884158590982\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0013\n",
      "Score: 1.3298264741897583\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout_1: 0.30000000000000004\n",
      "dense_units_1: 128\n",
      "dropout_2: 0.30000000000000004\n",
      "dense_units_2: 64\n",
      "lr: 0.0004427191803516009\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 1.3452163934707642\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1f3475f8ec4b9316\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1f3475f8ec4b9316\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $hpt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 32, 68)            4692      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 26, 16)            7632      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 13, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 13, 16)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 13, 8)             800       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 104)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               13440     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,873\n",
      "Trainable params: 60,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "name-clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5978f2f5b0a3ef0276425fba9a2a1232fa2fd501b13661a316074abcd0552b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
